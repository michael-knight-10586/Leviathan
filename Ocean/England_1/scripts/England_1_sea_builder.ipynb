{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eea6549-81d7-4340-a7ca-3aab9a352a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9394/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9495/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9596/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9697/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9798/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9899/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/9900/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0001/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0102/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0203/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0304/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0405/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0506/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0607/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0708/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0809/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/0910/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1011/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1112/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1213/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1314/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1415/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1516/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1617/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\1965663526.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1718/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1819/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/1920/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/2021/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/2122/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/2223/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/2324/E0.csv\n",
      "⬇️ Downloading https://www.football-data.co.uk/mmz4281/2425/E0.csv\n",
      "\n",
      "✅ Saved 12324 rows to all_e0_seasons_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "# Define all seasons\n",
    "years = [ '9394', '9495', '9596', '9697', '9798', '9899', '9900', '0001',\n",
    "          '0102', '0203', '0304', '0405', '0506', '0607', '0708', '0809',\n",
    "          '0910', '1011', '1112', '1213', '1314', '1415', '1516', '1617',\n",
    "          '1718', '1819', '1920', '2021', '2122', '2223', '2324', '2425']\n",
    "\n",
    "div = 'E0'\n",
    "all_dfs = []\n",
    "errors = []\n",
    "\n",
    "def safe_read_csv(url):\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    lines = r.content.decode(\"ISO-8859-1\").splitlines()\n",
    "\n",
    "    header = next(csv.reader([lines[0]]))\n",
    "    expected_cols = len(header)\n",
    "\n",
    "    df = pd.read_csv(StringIO(\"\\n\".join(lines)), usecols=range(expected_cols))\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "# Process each season\n",
    "for y in years:\n",
    "    url = f\"https://www.football-data.co.uk/mmz4281/{y}/{div}.csv\"\n",
    "    print(f\"⬇️ Downloading {url}\")\n",
    "    try:\n",
    "        df = safe_read_csv(url)\n",
    "\n",
    "        # Clean and parse dates\n",
    "        df.columns = df.columns.str.strip()\n",
    "        if 'Date' not in df.columns:\n",
    "            raise ValueError(\"Missing 'Date' column\")\n",
    "        df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "\n",
    "        # Sort by date to find actual season year from last match\n",
    "        df = df.sort_values('Date')\n",
    "        season_year = df['Date'].iloc[-1].year\n",
    "\n",
    "        df['Season'] = str(season_year)\n",
    "        df['Season_Div'] = f\"{season_year}_{div}\"\n",
    "\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {url}: {e}\")\n",
    "        errors.append((y, str(e)))\n",
    "\n",
    "# Combine and save\n",
    "combined = pd.concat(all_dfs, ignore_index=True, sort=False)\n",
    "combined.to_csv(\"../outputs/England_1_dload.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(combined)} England_1_dload.csv\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\n⚠️ Issues with the following seasons:\")\n",
    "    for year, msg in errors:\n",
    "        print(f\"- {year}: {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3cde7f-ad6a-448f-a3bb-a2a901be3393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  Rows\n",
      "0    1994   462\n",
      "1    1995   462\n",
      "2    1996   380\n",
      "3    1997   380\n",
      "4    1998   380\n",
      "5    1999   380\n",
      "6    2000   380\n",
      "7    2001   380\n",
      "8    2002   380\n",
      "9    2003   380\n",
      "10   2004   380\n",
      "11   2005   380\n",
      "12   2006   380\n",
      "13   2007   380\n",
      "14   2008   380\n",
      "15   2009   380\n",
      "16   2010   380\n",
      "17   2011   380\n",
      "18   2012   380\n",
      "19   2013   380\n",
      "20   2014   380\n",
      "21   2015   380\n",
      "22   2016   380\n",
      "23   2017   380\n",
      "24   2018   380\n",
      "25   2019   380\n",
      "26   2020   380\n",
      "27   2021   380\n",
      "28   2022   380\n",
      "29   2023   380\n",
      "30   2024   380\n",
      "31   2025   380\n"
     ]
    }
   ],
   "source": [
    "rows_per_season = (\n",
    "    combined.groupby(\"Season\", as_index=False)\n",
    "            .size()\n",
    "            .rename(columns={\"size\": \"Rows\"})\n",
    ")\n",
    "\n",
    "print(rows_per_season)\n",
    "\n",
    "rows_per_season.to_csv(\"../outputs/England_1_rows_per_season.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc752d9e-8abd-412a-9c4e-5a203aa9cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_30708\\221937131.py:5: DtypeWarning: Columns (0,131,189) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../outputs/England_1_dload.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved England_1_Plankton.csv\n",
      "Saved England_1_Krill.csv\n",
      "Saved England_1_Squid.csv\n",
      "Saved England_1_Turtle.csv\n",
      "Saved England_1_Dolphin.csv\n",
      "Saved England_1_Orca.csv\n",
      "Saved England_1_Sperm_whale.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Load combined data created earlier\n",
    "df = pd.read_csv(\"../outputs/England_1_dload.csv\")\n",
    "\n",
    "# Remove stray unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains(r'^Unnamed')]\n",
    "\n",
    "# Core column groups in intuitive order\n",
    "base      = ['Season', 'Div', 'Season_Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
    "ht        = ['HTHG', 'HTAG', 'HTR']\n",
    "match     = ['Referee', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF']\n",
    "\n",
    "wh_small  = ['WHH', 'WHD', 'WHA']\n",
    "wh_large  = wh_small + ['WHCH', 'WHCD', 'WHCA']\n",
    "vc_small  = ['VCH', 'VCD', 'VCA']\n",
    "vc_large  = vc_small + ['VCCH', 'VCCD', 'VCCA']\n",
    "b365_small= ['B365H', 'B365D', 'B365A']\n",
    "b365_large= b365_small + ['B365CH', 'B365CD', 'B365CA']\n",
    "\n",
    "p_small   = ['PSH', 'PSD', 'PSA', 'PSCH', 'PSCD', 'PSCA']\n",
    "p_extra   = ['P>2.5', 'P<2.5', 'PAHH', 'PAHA', 'PC>2.5', 'PC<2.5', 'PCAHA']\n",
    "\n",
    "datasets = {\n",
    "    'Plankton'   : base,\n",
    "    'Krill'      : base + ht,\n",
    "    'Squid'      : base + ht + match,\n",
    "    'Turtle'     : base + ht + match + wh_small + vc_small + b365_small,\n",
    "    'Dolphin'    : base + ht + match + wh_small + vc_small + b365_small + p_small,\n",
    "    'Orca'       : base + ht + match + wh_large + vc_large + b365_large + p_small + p_extra,\n",
    "    'Sperm_whale': base + ht + match + wh_large + vc_large + b365_large + p_small + p_extra,\n",
    "}\n",
    "\n",
    "# Ensure target folder exists\n",
    "os.makedirs(\"../outputs\", exist_ok=True)\n",
    "\n",
    "for creature, cols in datasets.items():\n",
    "    # keep only columns present in the dataframe, preserve order, drop duplicates\n",
    "    ordered = list(OrderedDict.fromkeys([c for c in cols if c in df.columns]))\n",
    "    df[ordered].to_csv(f\"../outputs/England_1_{creature}.csv\", index=False)\n",
    "    print(f\"Saved England_1_{creature}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4be7378-fcfa-4028-93b0-983719913aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             TotalRows  Season    Div  Season_Div   Date  HomeTeam  AwayTeam  \\\n",
      "Dataset                                                                        \n",
      "Plankton         12324   12324  11944       12324  12324     12324     12324   \n",
      "Krill            12324   12324  11944       12324  12324     12324     12324   \n",
      "Squid            12324   12324  11944       12324  12324     12324     12324   \n",
      "Turtle           12324   12324  11944       12324  12324     12324     12324   \n",
      "Dolphin          12324   12324  11944       12324  12324     12324     12324   \n",
      "Orca             12324   12324  11944       12324  12324     12324     12324   \n",
      "Sperm_whale      12324   12324  11944       12324  12324     12324     12324   \n",
      "\n",
      "              FTHG   FTAG    FTR  ...  B365CH  B365CD  B365CA   P>2.5   P<2.5  \\\n",
      "Dataset                           ...                                           \n",
      "Plankton     12324  12324  12324  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "Krill        12324  12324  12324  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "Squid        12324  12324  12324  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "Turtle       12324  12324  12324  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "Dolphin      12324  12324  12324  ...     NaN     NaN     NaN     NaN     NaN   \n",
      "Orca         12324  12324  12324  ...  2280.0  2280.0  2280.0  2268.0  2268.0   \n",
      "Sperm_whale  12324  12324  12324  ...  2280.0  2280.0  2280.0  2268.0  2268.0   \n",
      "\n",
      "               PAHH    PAHA  PC>2.5  PC<2.5   PCAHA  \n",
      "Dataset                                              \n",
      "Plankton        NaN     NaN     NaN     NaN     NaN  \n",
      "Krill           NaN     NaN     NaN     NaN     NaN  \n",
      "Squid           NaN     NaN     NaN     NaN     NaN  \n",
      "Turtle          NaN     NaN     NaN     NaN     NaN  \n",
      "Dolphin         NaN     NaN     NaN     NaN     NaN  \n",
      "Orca         2280.0  2280.0  2269.0  2269.0  2280.0  \n",
      "Sperm_whale  2280.0  2280.0  2269.0  2269.0  2280.0  \n",
      "\n",
      "[7 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "creatures = ['Plankton', 'Krill', 'Squid', 'Turtle', 'Dolphin', 'Orca', 'Sperm_whale']\n",
    "records   = []\n",
    "\n",
    "for c in creatures:\n",
    "    path = f\"../outputs/England_1_{c}.csv\"\n",
    "    df   = pd.read_csv(path)\n",
    "\n",
    "    stats          = df.notna().sum().to_dict()   # non-null counts per column\n",
    "    stats['TotalRows'] = len(df)\n",
    "    stats['Dataset']   = c\n",
    "    records.append(stats)\n",
    "\n",
    "# build summary, place TotalRows first\n",
    "summary = pd.DataFrame(records).set_index('Dataset')\n",
    "summary = summary[['TotalRows'] + [col for col in summary.columns if col != 'TotalRows']]\n",
    "\n",
    "print(summary)               # inspect before deciding to save\n",
    "summary.to_csv(\"../outputs/England_1_summary.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54e06707-7198-46af-8536-deca02dfb3a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebde55-cac9-4548-909b-85bb89cbe644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad4e79-ceb5-4934-ad4b-b5cb1c1c266e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
